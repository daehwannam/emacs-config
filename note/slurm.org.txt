
* Usage
** sinfo
   Check recource

   [Command]
   $ sinfo

   [Output]
   PARTITION  CPUS(A/I/O/T)  STATE  NODELIST  NODES GRES             MEMORY  TIMELIMIT   AVAIL_FEATURES
   2080ti*    4/76/0/80      mix    n[1-4]    4     gpu:GTX2080Ti:8  120000  3-00:00:00  (null)        
   titanrtx   2/38/0/40      mix    n[5,7]    2     gpu:TITANRTX:4   250000  3-00:00:00  (null)        
   titanrtx   0/88/0/88      idle   n[6,8-9]  3     gpu:TITANRTX:4   250000  3-00:00:00  (null)        
   titanxp    16/24/0/40     mix    n[10-11]  2     gpu:TITANXP:8    120000  3-00:00:00  (null)        
   titanxp    0/40/0/40      idle   n[12-13]  2     gpu:TITANXP:8    120000  3-00:00:00  (null)        

   [Details]
   - There exist 5 partitions, where each partition has several nodes
   - Information of CPUS indicates Allocated/Idle/Other/Total
   - TIMELIMIT indicate the maximum allowed time for each job (e.g. 3 days)

** squeue
   Check slurm queue

   [Commands]
   $ squeue

   [Output]
   JOBID  NAME          STATE     USER     GROUP    PARTITION  NODE NODELIST(REASON)  CPUS TRES_PER_NODE TIME_LIMIT  TIME_LEFT  
   51617  train-8x2080  RUNNING   aren     usercl4  2080ti     1    n2                1    gpu:8         3-00:00:00  2-07:15:18 
   51575  0.5.4.2.7p4   RUNNING   weebum   usercl4  titanxp    1    n11               2    gpu:1         2-23:00:00  1-00:50:06 
   51556  unfreeze      RUNNING   lee1jun  usercl4  titanxp    1    n10               8    gpu:8         3-00:00:00  7:42:58

   [Details]
   - State: running/pendding/cg
     - pendding: Job is waiting to run
     - cg: The job is done. It disappears soon

   [Other commands]
   $ scontrol show job [job_id]
   $ scontrol show node [running_node_name]

** Run
   - interactive: run shell with resources
   - batch: run batch script with resources
*** Interactive run
    [srun/salloc options]
    - p : partition 지정
    - N : 총 할당받을 노드개수
    - n, --ntasks : 실행할 task 개수
    - t, -time : 최대 실행시간
    --gress=gpu : 노드별 gpu 개수
**** srun only
     2 nodes, 2 gpu per node

     $ srun -p titanxp -N 2 -n 4  -t 00:30:00 --gres=gpu:2 --pty /bin/bash -l  # resource allocation
     $ exit  # exit from queue
**** salloc & srun
     1) Allocate resources with salloc
     2) Run tasks with srun

     $ salloc -N 1 -n 6  -t 00:30:00  /bin/bash -l  # resource allocation
     $ srun execution.sh  # run task with the resources
     $ exit  # exit from queue

*** Batch run
